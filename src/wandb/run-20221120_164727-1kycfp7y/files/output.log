  0%|                                                             | 0/780 [00:00<?, ?it/s]The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
Traceback (most recent call last):
  File "/home/nhtlong/playground/zalo-ai/applybigdata/shopee-reviews-sentiment-analysis/src/train.py", line 35, in <module>
    trainer.train()
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/trainer.py", line 1498, in train
    return inner_training_loop(
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/trainer.py", line 1714, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 530, in __next__
    data = self._next_data()
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 570, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/trainer_utils.py", line 696, in __call__
    return self.data_collator(features)
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/data/data_collator.py", line 67, in default_data_collator
    return torch_default_data_collator(features)
  File "/home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/data/data_collator.py", line 129, in torch_default_data_collator
    batch[k] = torch.stack([f[k] for f in features])
RuntimeError: stack expects each tensor to be equal size, but got [6] at entry 0 and [3] at entry 1
[31mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [39m[1mTraceback (most recent call last)[31m[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
[31mâ”‚[39m /home/nhtlong/playground/zalo-ai/applybigdata/shopee-reviews-sentiment-analysis/src/[1mtr[22m [31mâ”‚
[31mâ”‚[39m [1main.py[22m:[94m35[39m in [92m<module>[39m                                                                  [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m   32 â”‚   compute_metrics=compute_metrics,                                              [31mâ”‚
[31mâ”‚[39m   33 )                                                                                 [31mâ”‚
[31mâ”‚[39m   34                                                                                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m35 trainer.train()                                                                   [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/[1mtrainer.py[22m: [31mâ”‚
[31mâ”‚[39m [94m1498[39m in [92mtrain[39m                                                                          [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m   1495 â”‚   â”‚   inner_training_loop = find_executable_batch_size(                       [31mâ”‚
[31mâ”‚[39m   1496 â”‚   â”‚   â”‚   [96mself[39m._inner_training_loop, [96mself[39m._train_batch_size, args.auto_find_b [31mâ”‚
[31mâ”‚[39m   1497 â”‚   â”‚   )                                                                       [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1498 â”‚   â”‚   [94mreturn[39m inner_training_loop(                                             [31mâ”‚
[31mâ”‚[39m   1499 â”‚   â”‚   â”‚   args=args,                                                          [31mâ”‚
[31mâ”‚[39m   1500 â”‚   â”‚   â”‚   resume_from_checkpoint=resume_from_checkpoint,                      [31mâ”‚
[31mâ”‚[39m   1501 â”‚   â”‚   â”‚   trial=trial,                                                        [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/[1mtrainer.py[22m: [31mâ”‚
[31mâ”‚[39m [94m1714[39m in [92m_inner_training_loop[39m                                                           [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m   1711 â”‚   â”‚   â”‚   â”‚   [96mself[39m._load_rng_state(resume_from_checkpoint)                    [31mâ”‚
[31mâ”‚[39m   1712 â”‚   â”‚   â”‚                                                                       [31mâ”‚
[31mâ”‚[39m   1713 â”‚   â”‚   â”‚   step = -[94m1[39m                                                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m1714 â”‚   â”‚   â”‚   [94mfor[39m step, inputs [95min[39m [96menumerate[39m(epoch_iterator):                      [31mâ”‚
[31mâ”‚[39m   1715 â”‚   â”‚   â”‚   â”‚                                                                   [31mâ”‚
[31mâ”‚[39m   1716 â”‚   â”‚   â”‚   â”‚   # Skip past any already trained steps if resuming training      [31mâ”‚
[31mâ”‚[39m   1717 â”‚   â”‚   â”‚   â”‚   [94mif[39m steps_trained_in_current_epoch > [94m0[39m:                          [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/[1mdataloa[22m [31mâ”‚
[31mâ”‚[39m [1mder.py[22m:[94m530[39m in [92m__next__[39m                                                                 [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m    527 â”‚   â”‚   [94mwith[39m torch.autograd.profiler.record_function([96mself[39m._profile_name):       [31mâ”‚
[31mâ”‚[39m    528 â”‚   â”‚   â”‚   [94mif[39m [96mself[39m._sampler_iter [95mis[39m [94mNone[39m:                                      [31mâ”‚
[31mâ”‚[39m    529 â”‚   â”‚   â”‚   â”‚   [96mself[39m._reset()                                                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 530 â”‚   â”‚   â”‚   data = [96mself[39m._next_data()                                            [31mâ”‚
[31mâ”‚[39m    531 â”‚   â”‚   â”‚   [96mself[39m._num_yielded += [94m1[39m                                              [31mâ”‚
[31mâ”‚[39m    532 â”‚   â”‚   â”‚   [94mif[39m [96mself[39m._dataset_kind == _DatasetKind.Iterable [95mand[39m \                [31mâ”‚
[31mâ”‚[39m    533 â”‚   â”‚   â”‚   â”‚   â”‚   [96mself[39m._IterableDataset_len_called [95mis[39m [95mnot[39m [94mNone[39m [95mand[39m \          [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/[1mdataloa[22m [31mâ”‚
[31mâ”‚[39m [1mder.py[22m:[94m570[39m in [92m_next_data[39m                                                               [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m    567 â”‚                                                                               [31mâ”‚
[31mâ”‚[39m    568 â”‚   [94mdef[39m [92m_next_data[39m([96mself[39m):                                                       [31mâ”‚
[31mâ”‚[39m    569 â”‚   â”‚   index = [96mself[39m._next_index()  # may raise StopIteration                   [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 570 â”‚   â”‚   data = [96mself[39m._dataset_fetcher.fetch(index)  # may raise StopIteration    [31mâ”‚
[31mâ”‚[39m    571 â”‚   â”‚   [94mif[39m [96mself[39m._pin_memory:                                                    [31mâ”‚
[31mâ”‚[39m    572 â”‚   â”‚   â”‚   data = _utils.pin_memory.pin_memory(data)                           [31mâ”‚
[31mâ”‚[39m    573 â”‚   â”‚   [94mreturn[39m data                                                             [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/torch/utils/data/_utils/ [31mâ”‚
[31mâ”‚[39m [1mfetch.py[22m:[94m52[39m in [92mfetch[39m                                                                   [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m   49 â”‚   â”‚   â”‚   data = [[96mself[39m.dataset[idx] [94mfor[39m idx [95min[39m possibly_batched_index]          [31mâ”‚
[31mâ”‚[39m   50 â”‚   â”‚   [94melse[39m:                                                                     [31mâ”‚
[31mâ”‚[39m   51 â”‚   â”‚   â”‚   data = [96mself[39m.dataset[possibly_batched_index]                           [31mâ”‚
[31mâ”‚[39m [31mâ± [39m52 â”‚   â”‚   [94mreturn[39m [96mself[39m.collate_fn(data)                                              [31mâ”‚
[31mâ”‚[39m   53                                                                                   [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/[1mtrainer_uti[22m [31mâ”‚
[31mâ”‚[39m [1mls.py[22m:[94m696[39m in [92m__call__[39m                                                                  [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m   693 â”‚                                                                                [31mâ”‚
[31mâ”‚[39m   694 â”‚   [94mdef[39m [92m__call__[39m([96mself[39m, features: List[[96mdict[39m]):                                    [31mâ”‚
[31mâ”‚[39m   695 â”‚   â”‚   features = [[96mself[39m._remove_columns(feature) [94mfor[39m feature [95min[39m features]       [31mâ”‚
[31mâ”‚[39m [31mâ± [39m696 â”‚   â”‚   [94mreturn[39m [96mself[39m.data_collator(features)                                      [31mâ”‚
[31mâ”‚[39m   697                                                                                  [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/data/[1mdata_c[22m [31mâ”‚
[31mâ”‚[39m [1mollator.py[22m:[94m67[39m in [92mdefault_data_collator[39m                                                 [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m     64 â”‚   # on the whole batch.                                                       [31mâ”‚
[31mâ”‚[39m     65 â”‚                                                                               [31mâ”‚
[31mâ”‚[39m     66 â”‚   [94mif[39m return_tensors == [33m"pt"[39m:                                                  [31mâ”‚
[31mâ”‚[39m [31mâ± [39m  67 â”‚   â”‚   [94mreturn[39m torch_default_data_collator(features)                            [31mâ”‚
[31mâ”‚[39m     68 â”‚   [94melif[39m return_tensors == [33m"tf"[39m:                                                [31mâ”‚
[31mâ”‚[39m     69 â”‚   â”‚   [94mreturn[39m tf_default_data_collator(features)                               [31mâ”‚
[31mâ”‚[39m     70 â”‚   [94melif[39m return_tensors == [33m"np"[39m:                                                [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m /home/nhtlong/.conda/envs/kaggle/lib/python3.10/site-packages/transformers/data/[1mdata_c[22m [31mâ”‚
[31mâ”‚[39m [1mollator.py[22m:[94m129[39m in [92mtorch_default_data_collator[39m                                          [31mâ”‚
[31mâ”‚[39m                                                                                        [31mâ”‚
[31mâ”‚[39m    126 â”‚   [94mfor[39m k, v [95min[39m first.items():                                                  [31mâ”‚
[31mâ”‚[39m    127 â”‚   â”‚   [94mif[39m k [95mnot[39m [95min[39m ([33m"label"[39m, [33m"label_ids"[39m) [95mand[39m v [95mis[39m [95mnot[39m [94mNone[39m [95mand[39m [95mnot[39m [96misinstance[39m [31mâ”‚
[31mâ”‚[39m    128 â”‚   â”‚   â”‚   [94mif[39m [96misinstance[39m(v, torch.Tensor):                                     [31mâ”‚
[31mâ”‚[39m [31mâ± [39m 129 â”‚   â”‚   â”‚   â”‚   batch[k] = torch.stack([f[k] [94mfor[39m f [95min[39m features])                [31mâ”‚
[31mâ”‚[39m    130 â”‚   â”‚   â”‚   [94melse[39m:                                                               [31mâ”‚
[31mâ”‚[39m    131 â”‚   â”‚   â”‚   â”‚   batch[k] = torch.tensor([f[k] [94mfor[39m f [95min[39m features])               [31mâ”‚
[31mâ”‚[39m    132                                                                                 [31mâ”‚
[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[1mRuntimeError: [22mstack expects each tensor to be equal size, but got [1m[6][22m at entry [1m0[22m and [1m[3]
at entry [1m1