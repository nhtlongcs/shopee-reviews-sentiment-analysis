
  0%|                                                             | 0/160 [00:00<?, ?it/s]/home/nhtlong/miniconda3/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '




 20%|██████████▍                                         | 32/160 [00:11<00:30,  4.14it/s]The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 1000
  Batch size = 32

  f1_func = load_metric("precision")████████████████████▎ | 31/32 [00:03<00:00,  9.41it/s]
Downloading builder script: 7.55kB [00:00, 2.38MB/s]
Downloading builder script:   0%|                             | 0.00/2.58k [00:00<?, ?B/s]
Traceback (most recent call last):                            | 0.00/2.52k [00:00<?, ?B/s]
  File "/home/nhtlong/playground/zalo-ai/applybigdata/shopee-reviews-sentiment-analysis/src/train.py", line 77, in <module>
    trainer.train()
  File "/home/nhtlong/miniconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1501, in train
    return inner_training_loop(
  File "/home/nhtlong/miniconda3/lib/python3.9/site-packages/transformers/trainer.py", line 1841, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/nhtlong/miniconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2089, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/nhtlong/miniconda3/lib/python3.9/site-packages/transformers/trainer.py", line 2796, in evaluate
    output = eval_loop(
  File "/home/nhtlong/miniconda3/lib/python3.9/site-packages/transformers/trainer.py", line 3081, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "/home/nhtlong/playground/zalo-ai/applybigdata/shopee-reviews-sentiment-analysis/src/train.py", line 17, in compute_metrics
    precision = pr_func.compute(predictions=predictions,
KeyError: 'precision'